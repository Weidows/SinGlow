{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SingGlow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
      "If using 'conda activate' from a batch script, change your\n",
      "invocation to 'CALL conda.bat activate'.\n",
      "\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - cmd.exe\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%conda activate SinGlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_definitions import *\n",
    "from pipeline import *\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from data_loarder import *\n",
    "\n",
    "os.chdir(r'./runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_dir = \"./runs\"\n",
    "\n",
    "data_loader = SongDataLoader('real.tfrecords',tfrecord_dir=tfrecord_dir)\n",
    "data_loader.make(\"../SongDatabase/RealSinger\")\n",
    "# real_dataset = data_loader.load()\n",
    "real_dataset = data_loader.load(sampling_num=200)\n",
    "# del data_loader\n",
    "\n",
    "data_loader = SongDataLoader('virtual.tfrecords',tfrecord_dir=tfrecord_dir)\n",
    "data_loader.make(\"../SongDatabase/VirtualSinger\")\n",
    "virtual_dataset = data_loader.load(sampling_num=200)\n",
    "# del data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Step ?. the brain\n",
    "brain = Brain(SQUEEZE_FACTOR, K_GLOW, L_GLOW, WINDOW_LENGTH, CHANNEL_SIZE, LEARNING_RATE)\n",
    "\n",
    "# load weight if available\n",
    "brain.model(tf.random.uniform((2, WINDOW_LENGTH, 1, CHANNEL_SIZE), 0.05, 1), training=True)\n",
    "# CHECKPOINT_PATH = r'D:\\PlayGround\\research\\SinGlow\\checkpoints\\weights'\n",
    "# print(brain.load_weights(CHECKPOINT_PATH))\n",
    "\n",
    "# Canceled future for execute_request message before replies were done\n",
    "# The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click here for more info. View Jupyter log for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'brain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Repos\\0x_others\\Discover304\\SinGlow\\run.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/0x_others/Discover304/SinGlow/run.ipynb#ch0000005?line=9'>10</a>\u001b[0m real_z_results \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/0x_others/Discover304/SinGlow/run.ipynb#ch0000005?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(real_dataset):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Repos/0x_others/Discover304/SinGlow/run.ipynb#ch0000005?line=11'>12</a>\u001b[0m     real_z_results\u001b[39m.\u001b[39mappend(brain\u001b[39m.\u001b[39mforward(i)\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/0x_others/Discover304/SinGlow/run.ipynb#ch0000005?line=12'>13</a>\u001b[0m real_z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(np\u001b[39m.\u001b[39mmean,\u001b[39m0\u001b[39m,np\u001b[39m.\u001b[39marray(real_z_results))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repos/0x_others/Discover304/SinGlow/run.ipynb#ch0000005?line=13'>14</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(real_z_path,mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'brain' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# real z\n",
    "\n",
    "real_z_path = \"./real_z.pickle\"\n",
    "if os.path.exists(real_z_path):\n",
    "    with open(real_z_path,mode='rb') as f:\n",
    "        real_z = pickle.load(f)\n",
    "else:\n",
    "    real_z_results = []\n",
    "    for i in tqdm(real_dataset):\n",
    "        real_z_results.append(brain.forward(i).numpy()[0])\n",
    "    real_z = np.apply_along_axis(np.mean,0,np.array(real_z_results))\n",
    "    with open(real_z_path,mode='wb') as f:\n",
    "        pickle.dump(real_z, f)\n",
    "\n",
    "# # virtual z\n",
    "# if os.path.exists('virtual_z.pickle'):\n",
    "#     with open('virtual_z.pickle',mode='rb') as f:\n",
    "#         virtual_z = pickle.load(f)\n",
    "# else:\n",
    "#     virtual_z_results = []\n",
    "#     for i in tqdm(virtual_dataset):\n",
    "#         virtual_z_results.append(brain.forward(i).numpy()[0])\n",
    "\n",
    "#     virtual_z = np.apply_along_axis(np.mean,0,np.array(virtual_z_results))\n",
    "#     with open('virtual_z.pickle',mode='wb') as f:\n",
    "#         pickle.dump(virtual_z, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delta z\n",
    "# delta_z = real_z-virtual_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure, ax = plt.subplots(3)\n",
    "# figure.set_size_inches(12,9)\n",
    "# plt.subplots_adjust(hspace=1)\n",
    "\n",
    "# ax[0] = plt.plot(np.array(real_z))\n",
    "# # ax[1] = plt.plot(np.array(delta_z))\n",
    "# # ax[2] = plt.plot(np.array(virtual_z))\n",
    "\n",
    "# # librosa.display.waveplot(np.array(real_z), sr=SAMPLING_RATE, ax=ax[0])\n",
    "# # librosa.display.waveplot(np.array(delta_z), sr=SAMPLING_RATE, ax=ax[1])\n",
    "# # librosa.display.waveplot(np.array(virtual_z), sr=SAMPLING_RATE, ax=ax[2])\n",
    "\n",
    "# ax[0].set_title(\"real_z\")\n",
    "# # ax[1].set_title(\"delta_z\")\n",
    "# # ax[2].set_title(\"virtual_z\")\n",
    "# ax[0].set_ylim([-1,1])\n",
    "# # ax[1].set_ylim([-1,1])\n",
    "# # ax[2].set_ylim([-1,1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hobar\\anaconda3\\envs\\DeepLearningTF2\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'D:\\PlayGround\\research\\SinGlow\\runs')\n",
    "\n",
    "virtual_file_dir = r'D:\\PlayGround\\research\\SongDatabase\\TestSongs'\n",
    "name = 'virtual_align_short'\n",
    "pickle_file  = f'result_{name}.pickle'\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, mode='rb') as f:\n",
    "        y, sr = pickle.load(f)\n",
    "else:\n",
    "    y, sr = librosa.load(os.path.join(virtual_file_dir, name + '.mp3'))\n",
    "    with open(pickle_file, mode='wb') as f:\n",
    "        pickle.dump((y, sr), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.array([y[i*sr*WINDOW_SIZE:(i+1)*sr*WINDOW_SIZE] for i in range(len(y)//(sr*WINDOW_SIZE))] + [y[-sr*WINDOW_SIZE:]]).reshape((-1,sr*WINDOW_SIZE,1,1))\n",
    "ys = tf.image.resize(ys,[WINDOW_LENGTH,1]).numpy().reshape((-1,1,WINDOW_LENGTH,1,1))\n",
    "ys_dataset = tf.data.Dataset.from_tensor_slices(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]C:\\Users\\hobar\\anaconda3\\envs\\DeepLearningTF2\\lib\\site-packages\\keras\\legacy_tf_layers\\core.py:513: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "C:\\Users\\hobar\\anaconda3\\envs\\DeepLearningTF2\\lib\\site-packages\\keras\\engine\\base_layer.py:2215: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "100%|██████████| 47/47 [02:11<00:00,  2.81s/it]\n"
     ]
    }
   ],
   "source": [
    "result_ys = []\n",
    "for i in tqdm(ys_dataset):\n",
    "    result_z = (brain.forward(i)+real_z)/2 # 向量加法中点\n",
    "    result_ys+=list(tf.squeeze(brain.backward(result_z).numpy()))\n",
    "sf.write(f'result_{name}.wav', np.array(result_ys), SAMPLING_RATE, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test song merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file_dir = r'D:\\PlayGround\\research\\SongDatabase\\TestSongs'\n",
    "# name='virtual_align_short'\n",
    "# virtual_file_path = os.path.join(test_file_dir,name+'.pickle')\n",
    "# if os.path.exists(virtual_file_path):\n",
    "#     with open(virtual_file_path,mode='rb') as f:\n",
    "#         y = pickle.load(f)\n",
    "# else:\n",
    "#     y, sr = librosa.load(os.path.join(test_file_dir,name+'.mp3'))\n",
    "#     with open(virtual_file_path,mode='wb') as f:\n",
    "#         pickle.dump(y, f)\n",
    "# virtual_data = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name='real_short_pure_reference'\n",
    "# real_file_path = os.path.join(test_file_dir,name+'.pickle')\n",
    "# if os.path.exists(real_file_path):\n",
    "#     with open(real_file_path,mode='rb') as f:\n",
    "#         y = pickle.load(f)\n",
    "# else:\n",
    "#     y, sr = librosa.load(os.path.join(test_file_dir,name+'.mp3'))\n",
    "#     with open(real_file_path,mode='wb') as f:\n",
    "#         pickle.dump(y, f)\n",
    "# real_data = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real = np.array([real_data[i*22050*WINDOW_SIZE:(i+1)*22050*WINDOW_SIZE] for i in range(len(real_data)//(22050*WINDOW_SIZE))] + [real_data[-22050*WINDOW_SIZE:]]).reshape((-1,22050*WINDOW_SIZE,1,1))\n",
    "# real = tf.image.resize(real,[WINDOW_LENGTH,1]).numpy().reshape((-1,1,WINDOW_LENGTH,1,1))\n",
    "\n",
    "# virtual = np.array([virtual_data[i*22050*WINDOW_SIZE:(i+1)*22050*WINDOW_SIZE] for i in range(len(virtual_data)//(22050*WINDOW_SIZE))] + [real_data[-22050*WINDOW_SIZE:]]).reshape((-1,22050*WINDOW_SIZE,1,1))\n",
    "# virtual = tf.image.resize(virtual,[WINDOW_LENGTH,1]).numpy().reshape((-1,1,WINDOW_LENGTH,1,1))\n",
    "\n",
    "# ys_dataset = tf.data.Dataset.from_tensor_slices((virtual,real[:virtual.shape[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_ys = []\n",
    "# for virtual,real in tqdm(ys_dataset):\n",
    "#     virtual_forward = brain.forward(virtual)\n",
    "#     real_forward = brain.forward(real)\n",
    "#     result_z = virtual_forward/2 + real_forward/2\n",
    "#     result_ys+=list(tf.clip_by_value(tf.squeeze(brain.backward(result_z)),-1,1).numpy())\n",
    "# virtual_file_path = os.path.join(test_file_dir,'result.wav')\n",
    "# sf.write(virtual_file_path, np.array(result_ys), SAMPLING_RATE, subtype='PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8faf7328610876523a4e724188f9f8e34266025c0876869ab11d11b1ec3b5644"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
